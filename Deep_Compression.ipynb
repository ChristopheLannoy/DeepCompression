{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Compression: Compressing deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Introduction\n",
    "\n",
    "Une grande partie du succ√®s du deep learning provient de la construction de r√©seaux de neurones de plus en plus grands. Ces r√©seaux, de part leur complexit√© peuvent √™tre demandant en calcul et en m√©moire, ce qui les rend difficiles √† d√©ployer sur des syst√®mes embarqu√©s avec des ressources mat√©rielles limit√©es. La compression de mod√®le vise √† r√©duire la taille des mod√®les tout en minimisant la perte de pr√©cision ou de performance. Une application utile de ces techniques de compression est par exemple le fait de pouvoir impl√©menter ces r√©seaux sur de petit appareils comme nos t√©l√©phone en limitant l'espace de m√©moire requis, le temps d'ex√©cution et la puissance consomm√©e.\n",
    "\n",
    "\n",
    "\n",
    "Afin de r√©duire la taille et la complexit√© de ces r√©seau, l'article [[1]](#bib) pr√©sente une solution possible: la \"compression profonde\", un m√©thode en trois √©tapes: pruning, trained quantization et Huffman coding, qui ensemble permettent de r√©duire consid√©rablement (de 35x √† 49x) les besoins de stockage des r√©seaux de neurones sans en affecter leur pr√©cision. \n",
    "\n",
    "Ce notebook s'int√©resse donc √† la compression des r√©seaux de neurones et pr√©sente une impl√©mentation de deux des techniques pr√©sent√©es dans l'article : le pruning et la quantification des poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\32474\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\32474\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: pytorch-ignite in c:\\users\\32474\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: future in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "#au cas ou il ne serait as d√©j√† install√©\n",
    "!pip install torch torchvision pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\32474\\anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2. Importation des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commencons par importer les donn√©es de MNIST. La base de donn√©es MNIST repr√©sente des chiffres manuscrits et contient un ensemble de training de 60 000 exemples et un ensemble de test de 10 000 exemples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(len(trainset))\n",
    "print(len(testset))\n",
    "\n",
    "#afin d'avoir un temps d'ex√©cution pas trop important on ne prend qu'une partie des donn√©es\n",
    "trainset, _ = torch.utils.data.random_split(trainset, (10000, 50000))\n",
    "testset, _ = torch.utils.data.random_split(testset, (1000, 9000))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons √† quoi ressemble un √©l√©ment de notre set de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "for i in range(4):\n",
    "    l = labels[i].numpy()\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title('%s: %d' % (\"Valeur\",l ))\n",
    "    plt.imshow(images[i].numpy()[0], cmap='Greys')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pruning\n",
    "\n",
    "Les r√©seaux de neurones sont souvent sur-param√©tr√©s et de nombreuses connexions entre neurones ne jouent pas forc√©ment un r√¥le primordiale √† la bonne ex√©cution de celui-ci. \n",
    "\n",
    "L'√©lagage du r√©seau de neurones est une m√©thode de compression qui consiste √† supprimer des poids d'un mod√®le entra√Æn√©. Il existe diff√©rentes mani√®res d'√©laguer un r√©seau neuronal. \n",
    "\n",
    "- On peut supprimer des poids. Cela se fait en d√©finissant les param√®tres individuels √† z√©ro. On r√©duit le nombre de param√®tres dans le mod√®le tout en conservant la m√™me architecture. \n",
    "- On peut supprimer des n≈ìuds entiers du r√©seau. Cela rendrait l'architecture du r√©seau elle-m√™me plus petite, tout en visant √† conserver la pr√©cision du plus grand r√©seau initial.\n",
    "\n",
    "<img src=\"img/pruning.png\" width=\"50%\"> (¬© [[4]](#bib))\n",
    "# \n",
    "\n",
    "\n",
    "Nous allons reproduire dans ce notebook le r√©seau LeNet-300-100 et nous concentrer sur la premi√®re m√©thode, la suppression de certains poids. Ce r√©seau a d√©j√† √©t√© utilis√© dans plusieurs articles afin d'√©valuer la puissance et la qualit√© des m√©thodes de compression [[2]](#bib), [[3]](#bib). \n",
    "\n",
    "Il se compose de deux couches cach√©es de 300 et 100 neurones. Il y a 784 entr√©es (repr√©sentant les pixels d'une image de 28x28) et 10 sorties pour les chiffre de 0 √† 9.\n",
    "\n",
    "<img src=\"img/LeNet.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.fc1 = MaskedLinear(784, 300)\n",
    "        self.fc2 = MaskedLinear(300, 100)\n",
    "        self.fc3 = MaskedLinear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1.forward(x))\n",
    "        x = F.relu(self.fc2.forward(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir dans la cellule ci-dessus, nous allons d√©finir pour ce mod√®le notre propre classe pour repr√©senter une couche de neurones afin de pouvoir la manipuler plus facilement et lui ajouter des m√©thodes suppl√©mentaires.\n",
    "\n",
    "On aimerait en effet pouvoir supprimer par la suite certains poids (c-√†-d connexion entre deux neurones) dans le but de r√©duire la taille de notre mod√®le.\n",
    "\n",
    "Pour ce faire nous allons cr√©er un masque (composer de 0 ou de 1) de la m√™me taille que la matrice repr√©sentant les poids de la couche de neurones. Ce masque d√©termine si un poids particulier doit √™tre utilis√© ou non. Nous initialisons ce masque avec des 1 car nous commencerons par consid√©rer tous les poids et supprimerons les poids inutiles par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaskedLinear(nn.Module):\n",
    "    \"\"\"Applies a masked linear transformation to the incoming data: :math:`y = (A * M)x + b`\n",
    "\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            (out_features x in_features)\n",
    "        bias:   the learnable bias of the module of shape (out_features)\n",
    "        mask: the unlearnable mask for the weight.\n",
    "            It has the same shape as weight (out_features x in_features)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        \n",
    "        # Initialisation du masque avec des 1\n",
    "        self.mask = nn.Parameter(torch.ones([out_features, in_features]), requires_grad=False)\n",
    "        \n",
    "        #initioalisation des poids et biais\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Produit element par element entre les poids et le masque pour ignorer\n",
    "        # certaines connexions entre neurones\n",
    "        return F.linear(input, self.weight * self.mask, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        # Affichage des param√®tres du r√©seau\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'\n",
    "\n",
    "    def prune(self, threshold):\n",
    "        \"\"\"\n",
    "        Supprime les poids de la couche si ceux-ci sont inf√©rieurs au treshold\n",
    "        \"\"\"\n",
    "        # converti les tenseur vers numpy\n",
    "        tensor = self.weight.data.cpu().numpy()\n",
    "        mask = self.mask.data.cpu().numpy()\n",
    "        \n",
    "        #met un zero dans le masque (supprime la connexion) si le poids est inf√©rieur √† un treshold donn√©\n",
    "        new_mask = np.where(abs(tensor) < threshold, 0, mask) #0 si vrai, mask sinon\n",
    "        \n",
    "        # applique les nouveau poids et masque\n",
    "        self.weight.data = torch.from_numpy(tensor * new_mask)\n",
    "        self.mask.data = torch.from_numpy(new_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quels neurones ou connexions peut-on supprimer ?\n",
    "\n",
    "Un d√©fi majeur dans la suppression des poids est de d√©terminer lesquelles enlever. Il existe diff√©rentes heuristiques et m√©thodes pour d√©terminer quels param√®tres sont moins importants et peuvent √™tre supprim√©s avec un effet minimal sur la pr√©cision. Le but est de supprimer davantage de param√®tres moins importants.\n",
    "\n",
    "L'un des moyens les plus simples de compression est bas√© sur l'ampleur du poids. Supprimer un poids revient essentiellement √† le remettre √† z√©ro. On peut minimiser l'effet sur le r√©seau en supprimant les pond√©rations qui sont d√©j√† proches de z√©ro. Cela peut √™tre mis en ≈ìuvre en supprimant tous les poids inf√©rieurs (en valeur absolue) √† un certain seuil. \n",
    "\n",
    "\n",
    "Alternativement, on peut √©galement supprimer des neurones entiers comme le propose [[3]](#bib). Lors de l'ex√©cution d'un jeu de donn√©es via un r√©seau, certaines statistiques des activations peuvent √™tre observ√©es. Certains neurones produisent toujours des valeurs proches de z√©ro et ces neurones peuvent probablement √™tre supprim√©s avec peu d'impact sur le mod√®le. L‚Äôintuition est que si un neurone s‚Äôactive rarement avec une valeur √©lev√©e, il est rarement utilis√© dans la t√¢che du mod√®le.\n",
    "\n",
    "De plus la redondance des param√®tres entre deux neurone d'une m√™me couche peut signifier qu'un de ces neurones peut probablement √™tre supprim√©. Si deux neurones dans une couche ont des poids ou des activations tr√®s similaires, cela peut signifier qu'ils *font la m√™me chose*.  Par cette intuition, nous pouvons donc supprimer l'un des neurones tout en conservant une pr√©cision semblable.\n",
    "\n",
    "Id√©alement dans un r√©seau de neurones, tous les neurones ont des param√®tres uniques et des activations de sortie qui sont d'une ampleur significative (sinon on peut supprimer des connexions) et non redondantes (sinon on peut supprimer des neurones).\n",
    "\n",
    "Pour la suite de ce notebook nous nous concentrerons sur la suppression des connexions entre neurones en annulant les poids en question. La m√©thode *prune()* d√©finie ci-dessus permettra de supprimer les poids inf√©rieurs √† une certaine valeur de \"*treshold*\"\n",
    "\n",
    "\n",
    "Commencons par instancier notre r√©seau LeNet-300-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param name           Shape                          Type           \n",
      "----------------------------------------------------------------------\n",
      "fc1.weight           torch.Size([300, 784])         torch.float32  \n",
      "fc1.bias             torch.Size([300])              torch.float32  \n",
      "fc1.mask             torch.Size([300, 784])         torch.float32  \n",
      "fc2.weight           torch.Size([100, 300])         torch.float32  \n",
      "fc2.bias             torch.Size([100])              torch.float32  \n",
      "fc2.mask             torch.Size([100, 300])         torch.float32  \n",
      "fc3.weight           torch.Size([10, 100])          torch.float32  \n",
      "fc3.bias             torch.Size([10])               torch.float32  \n",
      "fc3.mask             torch.Size([10, 100])          torch.float32  \n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "\n",
    "#affiche les caract√©ristiques de notre mod√®le \n",
    "print(f\"{'Param name':20} {'Shape':30} {'Type':15}\")\n",
    "print('-'*70)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name:20} {str(param.shape):30} {str(param.dtype):15}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "initial_optimizer_state_dict = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant d√©finir les fonctions qui permettrons d'entrainer notre mod√®le et d'√©valuer la pr√©cision de celui-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(enumerate(trainloader), total=len(trainloader)) #pour une animation lors de l'entrainement du mod√®le\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data, target = data, target\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # zero-out all the gradients corresponding to the pruned connections\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'mask' in name:\n",
    "                    continue\n",
    "                tensor = p.data.cpu().numpy()\n",
    "                grad_tensor = p.grad.data.cpu().numpy()\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                p.grad.data = torch.from_numpy(grad_tensor)\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                done = batch_idx * len(data)\n",
    "                percentage = 100. * batch_idx / len(trainloader)\n",
    "                pbar.set_description(f'Train Epoch: {epoch} [{done:5}/{len(trainloader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de la pr√©cision du mod√®le avec les donn√©es de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        accuracy = 100. * correct / len(testloader.dataset)\n",
    "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)} ({accuracy:.2f}%)')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant d'afficher le pourcentage de connexions supprim√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nonzeros(model):\n",
    "    nonzero = total = 0\n",
    "    for name, p in model.named_parameters():\n",
    "        if 'mask' in name:\n",
    "            continue\n",
    "        tensor = p.data.cpu().numpy()\n",
    "        nz_count = np.count_nonzero(tensor)\n",
    "        total_params = np.prod(tensor.shape)\n",
    "        nonzero += nz_count\n",
    "        total += total_params\n",
    "        print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
    "    print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement initial du mod√®le\n",
    "\n",
    "Nous commencons par entrainer notre r√©seau complet avec tous les poids potentiellement non nuls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [ 9600/10000 ( 96%)]  Loss: 0.375352: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 79.83it/s]\n",
      "Train Epoch: 1 [ 9600/10000 ( 96%)]  Loss: 0.050324: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 72.85it/s]\n",
      "Train Epoch: 2 [ 9600/10000 ( 96%)]  Loss: 0.129923: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 73.36it/s]\n",
      "Train Epoch: 3 [ 9600/10000 ( 96%)]  Loss: 0.027568: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 69.86it/s]\n",
      "Train Epoch: 4 [ 9600/10000 ( 96%)]  Loss: 0.016607: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 76.72it/s]\n",
      "Train Epoch: 5 [ 9600/10000 ( 96%)]  Loss: 0.060555: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 77.82it/s]\n",
      "Train Epoch: 6 [ 9600/10000 ( 96%)]  Loss: 0.026022: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 84.36it/s]\n",
      "Train Epoch: 7 [ 9600/10000 ( 96%)]  Loss: 0.013111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 82.20it/s]\n",
      "Train Epoch: 8 [ 9600/10000 ( 96%)]  Loss: 0.056119: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 79.95it/s]\n",
      "Train Epoch: 9 [ 9600/10000 ( 96%)]  Loss: 0.006625: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 82.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initial training\n",
    "print(\"--- Initial training ---\")\n",
    "train(10) #nbr of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous regardons ensuite la pr√©cision de notre mod√®le et nous pouvons √©galement v√©rifier que la majorit√© des poids ne sont pas nul (On a en effet supprimer encore aucune connexion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before pruning ---\n",
      "Test set: Average loss: 0.0954, Accuracy: 974/1000 (97.40%)\n",
      "fc1.weight           | nonzeros =  235200 /  235200 (100.00%) | total_pruned =       0 | shape = (300, 784)\n",
      "fc1.bias             | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
      "fc2.weight           | nonzeros =   30000 /   30000 (100.00%) | total_pruned =       0 | shape = (100, 300)\n",
      "fc2.bias             | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
      "fc3.weight           | nonzeros =    1000 /    1000 (100.00%) | total_pruned =       0 | shape = (10, 100)\n",
      "fc3.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
      "alive: 266610, pruned : 0, total: 266610, Compression rate :       1.00x  (  0.00% pruned)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Before pruning ---\")\n",
    "test()\n",
    "print_nonzeros(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.8707e-02,  9.9229e-03, -1.2400e-02, -5.6901e-05, -5.1290e-02,\n",
      "         3.0853e-02,  7.1772e-02,  8.4386e-02, -1.0330e-02,  9.6612e-02,\n",
      "         7.5593e-02,  4.8359e-02,  1.3008e-02, -1.0121e-01,  2.9765e-03,\n",
      "        -1.1927e-02, -4.4987e-04, -1.5238e-01,  5.3286e-02,  8.4578e-02,\n",
      "         7.7271e-02, -4.4730e-02,  1.1816e-01, -7.6085e-02,  2.7984e-02,\n",
      "         1.0889e-01, -6.4700e-02,  1.1584e-01, -1.4126e-01,  1.3968e-01,\n",
      "         5.6004e-03, -5.8737e-02, -9.5116e-02,  1.2062e-01, -1.2430e-01,\n",
      "         2.8648e-03,  1.1506e-02,  1.2208e-01, -9.7791e-02, -7.3561e-02,\n",
      "        -1.7193e-01,  3.8486e-02, -1.1485e-01,  8.2517e-02,  3.4351e-02,\n",
      "        -2.1138e-01,  7.5399e-02,  8.1441e-02, -6.1288e-04, -7.7396e-02,\n",
      "         8.1734e-02,  6.6188e-02,  9.2524e-02, -1.4867e-01,  1.4140e-01,\n",
      "        -1.2114e-01, -1.5430e-01, -1.1504e-01, -1.5686e-01,  5.6746e-02,\n",
      "        -5.1209e-02, -1.8004e-01, -1.1146e-02, -1.6594e-01,  6.8720e-02,\n",
      "         4.3338e-02,  2.4284e-02, -4.5784e-02, -6.3460e-05,  4.0434e-02,\n",
      "         9.8205e-02, -7.5451e-02, -9.4863e-02,  8.0350e-02, -3.9205e-02,\n",
      "        -1.8715e-02, -4.3397e-02,  5.9710e-02,  3.9145e-02, -1.4998e-01,\n",
      "         1.1313e-02,  7.9215e-02,  9.8979e-03,  7.7004e-02,  1.2318e-02,\n",
      "         5.5701e-02,  6.6554e-02, -1.0730e-02, -1.2760e-01, -8.8571e-04,\n",
      "        -3.7339e-02, -1.6087e-01, -1.4104e-02,  2.4659e-02, -2.5857e-05,\n",
      "        -1.4135e-01,  1.1561e-01,  2.7217e-04, -3.7970e-02, -1.4075e-01],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "#poids d'un des neurone de la derni√®re couche\n",
    "print(model.fc3.weight[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression de certaine connexion\n",
    "\n",
    "Nous pouvons maintenant supprimer des connexions entre neurones dont le r√¥le serait peu important\n",
    "\n",
    "Une des m√©thodes possibles afin de d√©terminer le seuil √† partir duquel une connexion peut √™tre supprim√©e est pr√©sent√©e dans un article pr√©c√©dent du m√™me auteur Song Hang: *Learning both Weights and Connections for Efficient Neural Networks*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sParam'></a>\n",
    "Dans cette article **s** est d√©finit comme un param√®tre de qualit√© / valeur de sensibilit√©.\n",
    "Et le seuil de suppression est choisi comme ce param√®tre de qualit√© multipli√© par l'√©cart type des poids d'une couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning with threshold : 0.03382377326488495 for layer fc1\n",
      "Pruning with threshold : 0.05046878755092621 for layer fc2\n",
      "Pruning with threshold : 0.08708547800779343 for layer fc3\n"
     ]
    }
   ],
   "source": [
    "s = 1\n",
    "for name, module in model.named_modules():\n",
    "            if name in ['fc1', 'fc2', 'fc3']:\n",
    "                threshold = np.std(module.weight.data.cpu().numpy()) * s\n",
    "                print(f'Pruning with threshold : {threshold} for layer {name}')\n",
    "                module.prune(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After pruning ---\n",
      "Test set: Average loss: 0.1725, Accuracy: 944/1000 (94.40%)\n",
      "fc1.weight           | nonzeros =   56970 /  235200 ( 24.22%) | total_pruned =  178230 | shape = (300, 784)\n",
      "fc1.bias             | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
      "fc2.weight           | nonzeros =    8806 /   30000 ( 29.35%) | total_pruned =   21194 | shape = (100, 300)\n",
      "fc2.bias             | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
      "fc3.weight           | nonzeros =     361 /    1000 ( 36.10%) | total_pruned =     639 | shape = (10, 100)\n",
      "fc3.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
      "alive: 66547, pruned : 200063, total: 266610, Compression rate :       4.01x  ( 75.04% pruned)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- After pruning ---\")\n",
    "test()\n",
    "print_nonzeros(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note une faible baisse de la pr√©cision (de l'ordre de 3 %) pour un nombre important de parma√®tre supprim√©s (de l'odre de 75% !).\n",
    "\n",
    "On peut examiner √† nouveau les poids d'un des neurones de la couche de sortie et constater que la majorit√© des poids ont bien √©t√© annul√©s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0000,  0.0966,  0.0000,  0.0000,  0.0000, -0.1012,  0.0000, -0.0000,\n",
      "        -0.0000, -0.1524,  0.0000,  0.0000,  0.0000, -0.0000,  0.1182, -0.0000,\n",
      "         0.0000,  0.1089, -0.0000,  0.1158, -0.1413,  0.1397,  0.0000, -0.0000,\n",
      "        -0.0951,  0.1206, -0.1243,  0.0000,  0.0000,  0.1221, -0.0978, -0.0000,\n",
      "        -0.1719,  0.0000, -0.1149,  0.0000,  0.0000, -0.2114,  0.0000,  0.0000,\n",
      "        -0.0000, -0.0000,  0.0000,  0.0000,  0.0925, -0.1487,  0.1414, -0.1211,\n",
      "        -0.1543, -0.1150, -0.1569,  0.0000, -0.0000, -0.1800, -0.0000, -0.1659,\n",
      "         0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000,  0.0982, -0.0000,\n",
      "        -0.0949,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.1500,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "        -0.1276, -0.0000, -0.0000, -0.1609, -0.0000,  0.0000, -0.0000, -0.1414,\n",
      "         0.1156,  0.0000, -0.0000, -0.1408], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc3.weight[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R√©entrainement du mod√®le r√©duit\n",
    "\n",
    "Une fois la majorit√© des poids annul√©e on peut r√©entrainer notre r√©seau tout en maintenant les poids des connexions supprim√©es √† 0 gr√¢ce au masque cr√©e lors de la d√©finition de la classe **MaskedLinear** (repr√©sentant une couche de neurones et les connexions supprim√©es).\n",
    "\n",
    "<img src=\"img/pruning2.png\" width=\"20%\"> (¬© [[4]](#bib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retraining ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [ 9600/10000 ( 96%)]  Loss: 0.004569: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 64.80it/s]\n",
      "Train Epoch: 1 [ 9600/10000 ( 96%)]  Loss: 0.008640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 81.73it/s]\n",
      "Train Epoch: 2 [ 9600/10000 ( 96%)]  Loss: 0.002100: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 73.63it/s]\n",
      "Train Epoch: 3 [ 9600/10000 ( 96%)]  Loss: 0.020026: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 72.23it/s]\n",
      "Train Epoch: 4 [ 9600/10000 ( 96%)]  Loss: 0.005320: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 73.29it/s]\n",
      "Train Epoch: 5 [ 9600/10000 ( 96%)]  Loss: 0.002949: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 53.60it/s]\n",
      "Train Epoch: 6 [ 9600/10000 ( 96%)]  Loss: 0.005762: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 74.88it/s]\n",
      "Train Epoch: 7 [ 9600/10000 ( 96%)]  Loss: 0.001660: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 66.53it/s]\n",
      "Train Epoch: 8 [ 9600/10000 ( 96%)]  Loss: 0.000583: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:02<00:00, 73.36it/s]\n",
      "Train Epoch: 9 [ 9600/10000 ( 96%)]  Loss: 0.002763: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:01<00:00, 83.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After Retraining ---\n",
      "Test set: Average loss: 0.1145, Accuracy: 971/1000 (97.10%)\n",
      "fc1.weight           | nonzeros =   56970 /  235200 ( 24.22%) | total_pruned =  178230 | shape = (300, 784)\n",
      "fc1.bias             | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
      "fc2.weight           | nonzeros =    8806 /   30000 ( 29.35%) | total_pruned =   21194 | shape = (100, 300)\n",
      "fc2.bias             | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
      "fc3.weight           | nonzeros =     361 /    1000 ( 36.10%) | total_pruned =     639 | shape = (10, 100)\n",
      "fc3.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
      "alive: 66547, pruned : 200063, total: 266610, Compression rate :       4.01x  ( 75.04% pruned)\n"
     ]
    }
   ],
   "source": [
    "# Retrain\n",
    "print(\"--- Retraining ---\")\n",
    "optimizer.load_state_dict(initial_optimizer_state_dict) # Reset the optimizer\n",
    "train(10)\n",
    "\n",
    "print(\"--- After Retraining ---\")\n",
    "test()\n",
    "print_nonzeros(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve une pr√©cision acrue et qui d√©passe m√™me parfois la pr√©cision initiale alors qu'une grande partie des poids (~75%) ont √©t√© supprim√©s! (Ceci est d√ª au fait que nous n'avons pas entrain√© suffisament notre mod√®le initial pour atteindre une pr√©cision optimale afin que le code puisse tourner relativement vite)\n",
    "\n",
    "Vous pouvez jouer avec le param√®tre **s** ([ici](#sParam)) en l'augmentant et v√©rifier jusqu'√† quel niveau on peut supprimer des param√®tres du r√©seau tout en conservant sa pr√©cision. (Non mais vraiment faites-le c'est impressionnant üòâ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec2\">2. Trained quantization and weight sharing</a>\n",
    "\n",
    "Passons maintenant √† l'√©tape suivante de compression. (Si vous avez abus√© avec la param√®tre **s**  remettez le vers *1* et relancez les cellules pr√©c√©dentes: *Run* => *run all above selected cell* et attendez un petit peu)\n",
    "\n",
    "\n",
    "Le partage de poids permet de comprimer davantage le r√©seau en r√©duisant le\n",
    "nombre de bits requis pour repr√©senter chaque poids. Nous limitons le nombre de poids effectifs que nous avons besoin de\n",
    "stocker en ayant plusieurs connexions partageant le m√™me poids. Puis par la suite il est possible d'affiner ces poids partag√©s en entrainant √† nouveau le mod√®le.\n",
    "\n",
    "<img src=\"img/poid_partage.png\" width=\"50%\"> (¬© [[1]](#bib))\n",
    "\n",
    "Le partage de poids est illustr√© sur la figure ci-dessus. Supposons que nous ayons une couche qui a 4 neurones d'entr√©e et 4\n",
    "neurones de sortie, le poids est une matrice 4 √ó 4. A gauche se trouve la matrice de poids 4 √ó 4. Les poids sont quantifi√©s/regroup√©s en 4 groupes (4 couleurs),\n",
    "tous les poids dans le m√™me groupe partagent la m√™me valeur, donc pour chaque poids, il faut alors stocker uniquement\n",
    "un petit index dans une table de poids partag√©s. \n",
    "\n",
    "Le gain de m√©moire peut se calculer en exprimant le taux de compression analytiquement. Pour un r√©seau avec $n$ connexions, o√π chacune stocke son poids correspondant sur un espace m√©moire de $b$ bits, il faudra $nb$ bits pour stocker la matrice de poids.\n",
    "\n",
    "Si l'on regroupe ces poids en $k$ groupes, il nous faudra pour chaque connexion $log_2(k)$ bits pour stocker l'index renvoyant √† un de ces $k$ groupes ainsi que $kb$ bits pour stocker ces poids en question.\n",
    "\n",
    "Le taux de compression est donc donn√© par:\n",
    "\n",
    "$$ r = \\frac{nb}{n log_2(k) + kb}$$\n",
    "\n",
    "### Clustering\n",
    "\n",
    "Nous utilisons le clustering k-means pour identifier les poids partag√©s pour chaque couche du r√©seau, de sorte que tous les poids qui tombent dans le m√™me cluster partageront le m√™me poids. Les poids ne sont pas partag√©s entre couches. \n",
    "\n",
    "Nous partitionnons les $n$ poids originaux $W = {w_1, w_2, ..., w_n}$ en $k$ clusters $C = {c_1, c_2, ..., c_k}$ avec $n >> k$, en de minimisant la somme des carr√©s intra-cluster:\n",
    "\n",
    "$$\\arg\\limits_{C} \\min \\sum_{i=1} ^{k} \\sum_{w \\in c_i} |w - c_i|^2 $$\n",
    "\n",
    "##### Initialisation des centres\n",
    "\n",
    "L'initialisation des centres a un impact sur la qualit√© du clustering et affecte donc la pr√©cision de la pr√©diction du r√©seau. Il existe trois m√©thodes d'initialisation qui sont discut√© dans [[1]](#bib): \n",
    "\n",
    "- Forgy (al√©atoire), bas√©e sur une densit√© lin√©aire d'initialisation.\n",
    "\n",
    "- Initialisation bas√©e sur la fonction de distribution des poids.\n",
    "\n",
    "- L'initialisation lin√©aire:  Espace lin√©airement les centres de gravit√© entre les [min, max] des poids d'origine.\n",
    "\n",
    "Il en sort de [[1]](#bib) que la meilleur m√©thode est l'initialisation lin√©aire et nous allons donc l'impl√©menter dans la suite de ce notebook. Cette m√©thode d'initialisation est invariante √† la distribution des poids et est la plus dispers√©e par rapport aux deux premi√®res m√©thodes (les poids repr√©sentant les $k$ groupes sont les plus diff√©rents).\n",
    "\n",
    "Les poids plus √©lev√©s jouent un r√¥le plus important que les poids plus petits, mais les poids important sont moins nombreux. Ainsi pour l'initialisation Forgy et l'initialisation bas√©e sur la densit√©, tr√®s peu de centres de gravit√© ont une valeur √©lev√©e, ce qui se traduit par une mauvaise repr√©sentation de ces quelques grands poids. L'initialisation lin√©aire ne souffre pas de ce probl√®me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32474\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:932: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\32474\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:932: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\32474\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:932: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "\n",
    "bits = 4\n",
    "\n",
    "for module in model.children():\n",
    "        weight = module.weight.data.cpu().numpy()\n",
    "        shape = weight.shape\n",
    "        mat = csr_matrix(weight) if shape[0] < shape[1] else csc_matrix(weight)\n",
    "        min_ = min(mat.data)\n",
    "        max_ = max(mat.data)\n",
    "        space = np.linspace(min_, max_, num=2**bits)\n",
    "        kmeans = KMeans(n_clusters=len(space), init=space.reshape(-1,1), n_init=1, precompute_distances=True, algorithm=\"full\")\n",
    "        kmeans.fit(mat.data.reshape(-1,1))\n",
    "        new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(-1)\n",
    "        mat.data = new_weight\n",
    "        module.weight.data = torch.from_numpy(mat.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- accuacy after weight sharing ---\n",
      "Test set: Average loss: 0.1129, Accuracy: 972/1000 (97.20%)\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.1415,  0.0000,  0.0000,  0.0000, -0.1640,  0.0000,  0.0000,\n",
      "         0.0000, -0.2376,  0.0000,  0.0000,  0.0000,  0.0000,  0.1813,  0.0000,\n",
      "         0.0000,  0.1415,  0.0000,  0.2028, -0.2008,  0.2028,  0.0000,  0.0000,\n",
      "        -0.0890,  0.2238, -0.1297,  0.0000,  0.0000,  0.1632, -0.1640,  0.0000,\n",
      "        -0.2782,  0.0000, -0.2008,  0.0000,  0.0000, -0.2782,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.1415, -0.2008,  0.2238, -0.1640,\n",
      "        -0.2008, -0.2008, -0.2008,  0.0000,  0.0000, -0.2376,  0.0000, -0.2008,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1415,  0.0000,\n",
      "        -0.1640,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2008,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.2376,  0.0000,  0.0000, -0.2376,  0.0000,  0.0000,  0.0000, -0.2376,\n",
      "         0.1813,  0.0000,  0.0000, -0.1640], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('--- accuacy after weight sharing ---')\n",
    "test()\n",
    "print(model.fc3.weight[0])\n",
    "#print(model.fc3.mask[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malgr√© le fait que l'on ait group√© les poids en 16 cat√©gories (par couche), la pr√©cision de notre mod√®le ne \n",
    "A nouveau vous pouvez jouer avec le param√®tre **bits** et r√©duire le nombre de bits utilis√©s pour encoder les diff√©rents poids (c'est √† dire le nombre de cluster) et observer comment la pr√©cision du mod√®le √©volue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement\n",
    "\n",
    "Pour terminer cette √©tape du partage des poids, il peut √™tre int√©ressant d'entrainer √† nouveau notre mod√®le pour ajuster finement la valeur partag√©e de ces poids. Pour ce faire durant la back-propagation, les gradients de chaque poids d'un m√™me groupe sont additionn√©s afin de modifier le poids partag√©. Cette √©tape est explicit√©e dans la figure ci-dessous pour l'exemple pr√©c√©dent d'une matrice 4 x 4.\n",
    "\n",
    "<img src=\"img/finetuned.png\" width=\"50%\"> (¬© [[1]](#bib))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"bib\"> Bibliographie</a>\n",
    "\n",
    "[1] *Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding*, 2015, Song Han, Huizi Mao, William J. Dally\n",
    "\n",
    "[2] *Compact Neural Representation Using Attentive Network Pruning*, 2020, Mahdi Biparva, John Tsotsos.\n",
    "\n",
    "[3] *Noiseout: A simple way to prune neural networks*, arXiv preprint arXiv:1611.06211 (2016), Babaeizadeh, Mohammad, Paris Smaragdis, and Roy H. Campbell.\n",
    "\n",
    "[4] *Learning both Weights and Connections for Efficient Neural Networks*, 2015 Song Han, Jeff Pool, John Tran, William J. Dally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
