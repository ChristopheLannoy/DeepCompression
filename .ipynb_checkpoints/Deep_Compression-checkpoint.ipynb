{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Compression: Compressing deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Introduction\n",
    "\n",
    "Une grande partie du succès du deep learning provient de la construction de réseaux de neurones de plus en plus grands. Ces réseaux, de part leur complexité peuvent être demandant en calcul et en mémoire, ce qui les rend difficiles à déployer sur des systèmes embarqués avec des ressources matérielles limitées. La compression de modèle vise à réduire la taille des modèles tout en minimisant la perte de précision ou de performance. Une application utile de ces techniques de compression est par exemple le fait de pouvoir implémenter ces réseaux sur de petit appareils comme nos téléphone en limitant l'espace de mémoire requis, le temps d'exécution et la puissance consommée.\n",
    "\n",
    "\n",
    "\n",
    "Afind de réduire la taille et la complexité de ces réseau, l'article [[1]](#bib) présente une solution possible: la \"compression profonde\", un méthode en trois étapes: pruning, trained quantization et Huffman coding, qui ensemble permettent de réduire considérablement (de 35x à 49x) les besoins de stockage des réseaux de neurones sans en affecter leur précision. \n",
    "\n",
    "Ce notebook s'intéresse donc à la compression des réseaux de neurones et présente une implémentation de deux des techniques présentées dans l'article : le pruning et la quantification des poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\32474\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\32474\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: pytorch-ignite in c:\\users\\32474\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: future in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\32474\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "#au cas ou il ne serait as déjà installé\n",
    "!pip install torch torchvision pytorch-ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2. Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commencons par importer les données de MNIST. La base de données MNIST représente des chiffres manuscrits et contient un ensemble de training de 60 000 exemples et un ensemble de test de 10 000 exemples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(len(trainset))\n",
    "print(len(testset))\n",
    "\n",
    "#afin d'avoir un temps d'exécution pas trop important on ne prend qu'une partie des données\n",
    "trainset, _ = torch.utils.data.random_split(trainset, (10000, 50000))\n",
    "testset, _ = torch.utils.data.random_split(testset, (1000, 9000))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons à quoi ressemble un élément de notre set de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "for i in range(4):\n",
    "    l = labels[i].numpy()\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title('%s: %d' % (\"Valeur\",l ))\n",
    "    plt.imshow(images[i].numpy()[0], cmap='Greys')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pruning\n",
    "\n",
    "Les réseaux de neurones sont souvent sur-paramétrés et de nombreuses connexions entre neurones ne jouent pas forcément un rôle primordiale à la bonne exécution de celui-ci. \n",
    "\n",
    "L'élagage du réseau de neurones est une méthode de compression qui consiste à supprimer des poids d'un modèle entraîné. Il existe différentes manières d'élaguer un réseau neuronal. \n",
    "\n",
    "- On peut supprimer des poids. Cela se fait en définissant les paramètres individuels à zéro. On réduit le nombre de paramètres dans le modèle tout en conservant la même architecture. \n",
    "- On peut supprimer des nœuds entiers du réseau. Cela rendrait l'architecture du réseau elle-même plus petite, tout en visant à conserver la précision du plus grand réseau initial.\n",
    "\n",
    "<img src=\"img/pruning.png\" width=\"50%\"> (© [[4]](#bib))\n",
    "# \n",
    "\n",
    "\n",
    "Nous allons reproduire dans ce notebook le réseau LeNet-300-100 et nous concentrer sur la première méthode, la suppression de certains poids. Ce réseau a déjà été utilisé dans plusieurs articles afin d'évaluer la puissance et la qualité des méthodes de compression [[2]](#bib), [[3]](#bib). \n",
    "\n",
    "Il se compose de deux couches cachées de 300 et 100 neurones. Il y a 784 entrées (représentant les pixels d'une image de 28x28) et 10 sorties pour les chiffre de 0 à 9.\n",
    "\n",
    "<img src=\"img/LeNet.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.fc1 = MaskedLinear(784, 300)\n",
    "        self.fc2 = MaskedLinear(300, 100)\n",
    "        self.fc3 = MaskedLinear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1.forward(x))\n",
    "        x = F.relu(self.fc2.forward(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir dans la cellule ci-dessus, nous allons définir pour ce modèle notre propre classe pour représenter une couche de neurones afin de pouvoir la manipuler plus facilement et lui ajouter des méthodes supplémentaires.\n",
    "\n",
    "On aimerait en effet pouvoir supprimer par la suite certains poids (c-à-d connexion entre deux neurones) dans le but de réduire la taille de notre modèle.\n",
    "\n",
    "Pour ce faire nous allons créer un masque (composer de 0 ou de 1) de la même taille que la matrice représentant les poids de la couche de neurones. Ce masque détermine si un poids particulier doit être utilisé ou non. Nous initialisons ce masque avec des 1 car nous commencerons par considérer tous les poids et supprimerons les poids inutiles par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MaskedLinear(nn.Module):\n",
    "    \"\"\"Applies a masked linear transformation to the incoming data: :math:`y = (A * M)x + b`\n",
    "\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            (out_features x in_features)\n",
    "        bias:   the learnable bias of the module of shape (out_features)\n",
    "        mask: the unlearnable mask for the weight.\n",
    "            It has the same shape as weight (out_features x in_features)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        \n",
    "        # Initialisation du masque avec des 1\n",
    "        self.mask = nn.Parameter(torch.ones([out_features, in_features]), requires_grad=False)\n",
    "        \n",
    "        #initioalisation des poids et biais\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Produit element par element entre les poids et le masque pour ignorer\n",
    "        # certaines connexions entre neurones\n",
    "        return F.linear(input, self.weight * self.mask, self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        # Affichage des paramètres du réseau\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'\n",
    "\n",
    "    def prune(self, threshold):\n",
    "        \"\"\"\n",
    "        Supprime les poids de la couche si ceux-ci sont inférieurs au treshold\n",
    "        \"\"\"\n",
    "        # converti les tenseur vers numpy\n",
    "        tensor = self.weight.data.cpu().numpy()\n",
    "        mask = self.mask.data.cpu().numpy()\n",
    "        \n",
    "        #met un zero dans le masque (supprime la connexion) si le poids est inférieur à un treshold donné\n",
    "        new_mask = np.where(abs(tensor) < threshold, 0, mask) #0 si vrai, mask sinon\n",
    "        \n",
    "        # applique les nouveau poids et masque\n",
    "        self.weight.data = torch.from_numpy(tensor * new_mask)\n",
    "        self.mask.data = torch.from_numpy(new_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quels neurones ou connexions peut-on supprimer ?\n",
    "\n",
    "Un défi majeur dans la suppression des poids est de déterminer lesquelles enlever. Il existe différentes heuristiques et méthodes pour déterminer quels paramètres sont moins importants et peuvent être supprimés avec un effet minimal sur la précision. Le but est de supprimer davantage de paramètres moins importants.\n",
    "\n",
    "L'un des moyens les plus simples de compression est basé sur l'ampleur du poids. Supprimer un poids revient essentiellement à le remettre à zéro. On peut minimiser l'effet sur le réseau en supprimant les pondérations qui sont déjà proches de zéro. Cela peut être mis en œuvre en supprimant tous les poids inférieurs (en valeur absolue) à un certain seuil. \n",
    "\n",
    "\n",
    "Alternativement, on peut également supprimer des neurones entiers comme le propose [[3]](#bib). Lors de l'exécution d'un jeu de données via un réseau, certaines statistiques des activations peuvent être observées. Certains neurones produisent toujours des valeurs proches de zéro et ces neurones peuvent probablement être supprimés avec peu d'impact sur le modèle. L’intuition est que si un neurone s’active rarement avec une valeur élevée, il est rarement utilisé dans la tâche du modèle.\n",
    "\n",
    "De plus la redondance des paramètres entre deux neurone d'une même couche peut signifier qu'un de ces neurones peut probablement être supprimé. Si deux neurones dans une couche ont des poids ou des activations très similaires, cela peut signifier qu'ils *font la même chose*.  Par cette intuition, nous pouvons donc supprimer l'un des neurones tout en conservant une précision semblable.\n",
    "\n",
    "Idéalement dans un réseau de neurones, tous les neurones ont des paramètres uniques et des activations de sortie qui sont d'une ampleur significative (sinon on peut supprimer des connexions) et non redondantes (sinon on peut supprimer des neurones).\n",
    "\n",
    "Pour la suite de ce notebook nous nous concentrerons sur la suppression des connexions entre neurones en annulant les poids en question. La méthode *prune()* définie ci-dessus permettra de supprimer les poids inférieurs à une certaine valeur de \"*treshold*\"\n",
    "\n",
    "\n",
    "Commencons par instancier notre réseau LeNet-300-100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param name           Shape                          Type           \n",
      "----------------------------------------------------------------------\n",
      "fc1.weight           torch.Size([300, 784])         torch.float32  \n",
      "fc1.bias             torch.Size([300])              torch.float32  \n",
      "fc1.mask             torch.Size([300, 784])         torch.float32  \n",
      "fc2.weight           torch.Size([100, 300])         torch.float32  \n",
      "fc2.bias             torch.Size([100])              torch.float32  \n",
      "fc2.mask             torch.Size([100, 300])         torch.float32  \n",
      "fc3.weight           torch.Size([10, 100])          torch.float32  \n",
      "fc3.bias             torch.Size([10])               torch.float32  \n",
      "fc3.mask             torch.Size([10, 100])          torch.float32  \n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "\n",
    "#affiche les caractéristiques de notre modèle \n",
    "print(f\"{'Param name':20} {'Shape':30} {'Type':15}\")\n",
    "print('-'*70)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f'{name:20} {str(param.shape):30} {str(param.dtype):15}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "initial_optimizer_state_dict = optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant définir les fonctions qui permettrons d'entrainer notre modèle et d'évaluer la précision de celui-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(enumerate(trainloader), total=len(trainloader)) #pour une animation lors de l'entrainement du modèle\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data, target = data, target\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            # zero-out all the gradients corresponding to the pruned connections\n",
    "            for name, p in model.named_parameters():\n",
    "                if 'mask' in name:\n",
    "                    continue\n",
    "                tensor = p.data.cpu().numpy()\n",
    "                grad_tensor = p.grad.data.cpu().numpy()\n",
    "                grad_tensor = np.where(tensor==0, 0, grad_tensor)\n",
    "                p.grad.data = torch.from_numpy(grad_tensor)\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                done = batch_idx * len(data)\n",
    "                percentage = 100. * batch_idx / len(trainloader)\n",
    "                pbar.set_description(f'Train Epoch: {epoch} [{done:5}/{len(trainloader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de la précision du modèle avec les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        accuracy = 100. * correct / len(testloader.dataset)\n",
    "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(testloader.dataset)} ({accuracy:.2f}%)')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction permettant d'afficher le pourcentage de connexions supprimées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nonzeros(model):\n",
    "    nonzero = total = 0\n",
    "    for name, p in model.named_parameters():\n",
    "        if 'mask' in name:\n",
    "            continue\n",
    "        tensor = p.data.cpu().numpy()\n",
    "        nz_count = np.count_nonzero(tensor)\n",
    "        total_params = np.prod(tensor.shape)\n",
    "        nonzero += nz_count\n",
    "        total += total_params\n",
    "        print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
    "    print(f'alive: {nonzero}, pruned : {total - nonzero}, total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainement initial du modèle\n",
    "\n",
    "Nous commencons par entrainer notre réseau complet avec tous les poids potentiellement non nuls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initial training ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [ 9600/10000 ( 96%)]  Loss: 0.226532: 100%|██████████| 157/157 [00:01<00:00, 86.07it/s]\n",
      "Train Epoch: 1 [ 9600/10000 ( 96%)]  Loss: 0.262379: 100%|██████████| 157/157 [00:01<00:00, 86.45it/s]\n",
      "Train Epoch: 2 [ 9600/10000 ( 96%)]  Loss: 0.089725: 100%|██████████| 157/157 [00:01<00:00, 85.00it/s]\n",
      "Train Epoch: 3 [ 9600/10000 ( 96%)]  Loss: 0.164269: 100%|██████████| 157/157 [00:01<00:00, 84.09it/s]\n",
      "Train Epoch: 4 [ 9600/10000 ( 96%)]  Loss: 0.049866: 100%|██████████| 157/157 [00:01<00:00, 83.82it/s]\n",
      "Train Epoch: 5 [ 9600/10000 ( 96%)]  Loss: 0.008324: 100%|██████████| 157/157 [00:01<00:00, 82.59it/s]\n",
      "Train Epoch: 6 [ 9600/10000 ( 96%)]  Loss: 0.064978: 100%|██████████| 157/157 [00:01<00:00, 83.51it/s]\n",
      "Train Epoch: 7 [ 9600/10000 ( 96%)]  Loss: 0.008139: 100%|██████████| 157/157 [00:02<00:00, 63.77it/s]\n",
      "Train Epoch: 8 [ 9600/10000 ( 96%)]  Loss: 0.037556: 100%|██████████| 157/157 [00:02<00:00, 70.69it/s]\n",
      "Train Epoch: 9 [ 9600/10000 ( 96%)]  Loss: 0.004804: 100%|██████████| 157/157 [00:02<00:00, 68.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initial training\n",
    "print(\"--- Initial training ---\")\n",
    "train(10) #nbr of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous regardons ensuite la précision de notre modèle et nous pouvons également vérifier que la majorité des poids ne sont pas nul (On a en effet supprimer encore aucune connexion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before pruning ---\n",
      "Test set: Average loss: 0.1205, Accuracy: 960/1000 (96.00%)\n",
      "fc1.weight           | nonzeros =  235200 /  235200 (100.00%) | total_pruned =       0 | shape = (300, 784)\n",
      "fc1.bias             | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
      "fc2.weight           | nonzeros =   30000 /   30000 (100.00%) | total_pruned =       0 | shape = (100, 300)\n",
      "fc2.bias             | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
      "fc3.weight           | nonzeros =    1000 /    1000 (100.00%) | total_pruned =       0 | shape = (10, 100)\n",
      "fc3.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
      "alive: 266610, pruned : 0, total: 266610, Compression rate :       1.00x  (  0.00% pruned)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"--- Before pruning ---\")\n",
    "test()\n",
    "print_nonzeros(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2855e-01,  9.3233e-03,  5.1379e-02,  2.5067e-03, -1.0679e-01,\n",
      "        -1.2737e-01, -1.7634e-01,  7.1766e-02, -5.4110e-02, -2.2599e-02,\n",
      "         3.0708e-02,  7.7443e-02, -1.3909e-01, -1.0321e-01,  1.3356e-01,\n",
      "         5.6316e-02, -1.2379e-01,  1.6111e-02,  1.0803e-01,  1.1702e-02,\n",
      "        -1.2034e-01, -4.0246e-06, -1.8994e-01,  1.0060e-01,  2.6636e-02,\n",
      "        -9.2831e-02,  6.3844e-02, -1.8141e-01,  1.0896e-02,  7.9720e-02,\n",
      "        -2.2416e-01,  6.1583e-02,  5.5610e-02, -2.0210e-01,  4.7807e-02,\n",
      "        -4.3350e-02, -3.1041e-02, -1.5713e-01, -7.0886e-02,  1.1595e-01,\n",
      "         8.4051e-02, -9.8285e-02, -2.2577e-01,  1.3870e-02, -1.0004e-01,\n",
      "        -8.2418e-02, -1.5100e-01, -1.1851e-01,  1.0698e-01,  3.5012e-02,\n",
      "         1.2974e-01,  1.3984e-02, -1.0424e-01,  7.1005e-02,  7.0859e-02,\n",
      "        -1.0685e-01,  3.5640e-02,  1.6987e-01,  2.6905e-02, -3.4537e-02,\n",
      "        -1.0435e-01,  9.0638e-02, -6.4744e-02,  8.5463e-02, -5.0013e-02,\n",
      "        -1.9224e-01,  9.7779e-02, -5.4408e-02,  8.1607e-02, -4.7193e-02,\n",
      "        -7.7194e-02, -6.7946e-02,  6.0980e-02, -8.9589e-02, -2.9349e-02,\n",
      "         1.1816e-01, -1.9097e-01, -3.4429e-02,  1.0362e-01,  5.7868e-02,\n",
      "        -1.2330e-01, -1.0213e-01,  2.9615e-02,  2.9346e-02,  9.3845e-02,\n",
      "         5.6041e-02,  8.2488e-02,  5.2093e-02,  4.3891e-02, -3.2643e-02,\n",
      "         5.8573e-11,  8.3582e-02,  9.2035e-02,  1.0809e-01,  8.2500e-02,\n",
      "        -7.5602e-02,  4.5407e-02,  9.7199e-02, -2.7868e-03,  1.6453e-02],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "#poids d'un des neurone de la dernière couche\n",
    "print(model.fc3.weight[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression de certaine connexion\n",
    "\n",
    "Nous pouvons maintenant supprimer des connexions entre neurones dont le rôle serait peu important\n",
    "\n",
    "Une des méthodes possibles afin de déterminer le seuil à partir duquel une connexion peut être supprimée est présentée dans un article précédent du même auteur Song Hang: *Learning both Weights and Connections for Efficient Neural Networks*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sParam'></a>\n",
    "Dans cette article **s** est définit comme un paramètre de qualité / valeur de sensibilité.\n",
    "Et le seuil de suppression est choisi comme ce paramètre de qualité multiplié par l'écart type des poids d'une couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning with threshold : 0.033417098224163055 for layer fc1\n",
      "Pruning with threshold : 0.050385624170303345 for layer fc2\n",
      "Pruning with threshold : 0.08917985111474991 for layer fc3\n"
     ]
    }
   ],
   "source": [
    "s = 1\n",
    "for name, module in model.named_modules():\n",
    "            if name in ['fc1', 'fc2', 'fc3']:\n",
    "                threshold = np.std(module.weight.data.cpu().numpy()) * s\n",
    "                print(f'Pruning with threshold : {threshold} for layer {name}')\n",
    "                module.prune(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After pruning ---\n",
      "Test set: Average loss: 0.1907, Accuracy: 940/1000 (94.00%)\n",
      "fc1.weight           | nonzeros =   56757 /  235200 ( 24.13%) | total_pruned =  178443 | shape = (300, 784)\n",
      "fc1.bias             | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
      "fc2.weight           | nonzeros =    9096 /   30000 ( 30.32%) | total_pruned =   20904 | shape = (100, 300)\n",
      "fc2.bias             | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
      "fc3.weight           | nonzeros =     378 /    1000 ( 37.80%) | total_pruned =     622 | shape = (10, 100)\n",
      "fc3.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
      "alive: 66641, pruned : 199969, total: 266610, Compression rate :       4.00x  ( 75.00% pruned)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- After pruning ---\")\n",
    "test()\n",
    "print_nonzeros(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note une faible baisse de la précision (de l'ordre de 3 %) pour un nombre important de parmaètre supprimés (de l'odre de 80% !).\n",
    "\n",
    "On peut examiner à nouveau les poids d'un des neurones de la couche de sortie et constater que la majorité des poids ont bien été annulés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1285,  0.0000,  0.0000,  0.0000, -0.1068, -0.1274, -0.1763,  0.0000,\n",
      "        -0.0000, -0.0000,  0.0000,  0.0000, -0.1391, -0.1032,  0.1336,  0.0000,\n",
      "        -0.1238,  0.0000,  0.1080,  0.0000, -0.1203, -0.0000, -0.1899,  0.1006,\n",
      "         0.0000, -0.0928,  0.0000, -0.1814,  0.0000,  0.0000, -0.2242,  0.0000,\n",
      "         0.0000, -0.2021,  0.0000, -0.0000, -0.0000, -0.1571, -0.0000,  0.1160,\n",
      "         0.0000, -0.0983, -0.2258,  0.0000, -0.1000, -0.0000, -0.1510, -0.1185,\n",
      "         0.1070,  0.0000,  0.1297,  0.0000, -0.1042,  0.0000,  0.0000, -0.1068,\n",
      "         0.0000,  0.1699,  0.0000, -0.0000, -0.1043,  0.0906, -0.0000,  0.0000,\n",
      "        -0.0000, -0.1922,  0.0978, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,\n",
      "         0.0000, -0.0896, -0.0000,  0.1182, -0.1910, -0.0000,  0.1036,  0.0000,\n",
      "        -0.1233, -0.1021,  0.0000,  0.0000,  0.0938,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0000,  0.0000,  0.0000,  0.0920,  0.1081,  0.0000, -0.0000,\n",
      "         0.0000,  0.0972, -0.0000,  0.0000], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc3.weight[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réentrainement du modèle réduit\n",
    "\n",
    "Une fois la majorité des poids annulée on peut réentrainer notre réseau tout en maintenant les poids des connexions supprimées à 0 grâce au masque crée lors de la définition de la classe **MaskedLinear** (représentant une couche de neurones et les connexions supprimées).\n",
    "\n",
    "<img src=\"img/pruning2.png\" width=\"20%\"> (© [[4]](#bib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retraining ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [ 9600/10000 ( 96%)]  Loss: 0.015291: 100%|██████████| 157/157 [00:02<00:00, 77.85it/s]\n",
      "Train Epoch: 1 [ 9600/10000 ( 96%)]  Loss: 0.002214: 100%|██████████| 157/157 [00:02<00:00, 78.13it/s]\n",
      "Train Epoch: 2 [ 9600/10000 ( 96%)]  Loss: 0.006990: 100%|██████████| 157/157 [00:02<00:00, 73.15it/s]\n",
      "Train Epoch: 3 [ 9600/10000 ( 96%)]  Loss: 0.002239: 100%|██████████| 157/157 [00:02<00:00, 60.52it/s]\n",
      "Train Epoch: 4 [ 9600/10000 ( 96%)]  Loss: 0.001950: 100%|██████████| 157/157 [00:02<00:00, 72.41it/s]\n",
      "Train Epoch: 5 [ 9600/10000 ( 96%)]  Loss: 0.007189: 100%|██████████| 157/157 [00:02<00:00, 73.84it/s]\n",
      "Train Epoch: 6 [ 9600/10000 ( 96%)]  Loss: 0.000771: 100%|██████████| 157/157 [00:02<00:00, 72.39it/s]\n",
      "Train Epoch: 7 [ 9600/10000 ( 96%)]  Loss: 0.007741: 100%|██████████| 157/157 [00:02<00:00, 72.74it/s]\n",
      "Train Epoch: 8 [ 9600/10000 ( 96%)]  Loss: 0.001056: 100%|██████████| 157/157 [00:02<00:00, 75.87it/s]\n",
      "Train Epoch: 9 [ 9600/10000 ( 96%)]  Loss: 0.000763: 100%|██████████| 157/157 [00:02<00:00, 67.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- After Retraining ---\n",
      "Test set: Average loss: 0.0975, Accuracy: 971/1000 (97.10%)\n",
      "fc1.weight           | nonzeros =   56757 /  235200 ( 24.13%) | total_pruned =  178443 | shape = (300, 784)\n",
      "fc1.bias             | nonzeros =     300 /     300 (100.00%) | total_pruned =       0 | shape = (300,)\n",
      "fc2.weight           | nonzeros =    9096 /   30000 ( 30.32%) | total_pruned =   20904 | shape = (100, 300)\n",
      "fc2.bias             | nonzeros =     100 /     100 (100.00%) | total_pruned =       0 | shape = (100,)\n",
      "fc3.weight           | nonzeros =     378 /    1000 ( 37.80%) | total_pruned =     622 | shape = (10, 100)\n",
      "fc3.bias             | nonzeros =      10 /      10 (100.00%) | total_pruned =       0 | shape = (10,)\n",
      "alive: 66641, pruned : 199969, total: 266610, Compression rate :       4.00x  ( 75.00% pruned)\n"
     ]
    }
   ],
   "source": [
    "# Retrain\n",
    "print(\"--- Retraining ---\")\n",
    "optimizer.load_state_dict(initial_optimizer_state_dict) # Reset the optimizer\n",
    "train(10)\n",
    "\n",
    "print(\"--- After Retraining ---\")\n",
    "test()\n",
    "print_nonzeros(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On retrouve une précision acrue et qui dépasse même la précision initiale alors qu'une grande partie des poids (~80%) ont été supprimés! (Ceci est dû au fait que nous n'avons pas entrainé suffisament notre modèle initial pour atteindre une précision optimale afin que le code puisse tourner relativement vite)\n",
    "\n",
    "Vous pouvez jouer avec le paramètre **s** ([ici](#sParam)) en l'augmentant et vérifier jusqu'à quel niveau on peut supprimer des paramètres du réseau tout en conservant sa précision. (Non mais vraiment faites-le c'est impressionnant 😉 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"sec2\">2. Trained quantization and weight sharing</a>\n",
    "\n",
    "Passons maintenant à l'étape suivante de compression. (Si vous avez abusé avec la paramètre **s**  remettez le vers *1* et relancez les cellules précédentes: *Run* => *run all above selected cell* et attendez un petit peu)\n",
    "\n",
    "\n",
    "Le partage de poids permet de comprimer davantage le réseau en réduisant le\n",
    "nombre de bits requis pour représenter chaque poids. Nous limitons le nombre de poids effectifs que nous avons besoin de\n",
    "stocker en ayant plusieurs connexions partageant le même poids. Puis par la suite il est possible d'affiner ces poids partagés en entrainant à nouveau le modèle.\n",
    "\n",
    "<img src=\"img/poid_partage.png\" width=\"50%\"> (© [[1]](#bib))\n",
    "\n",
    "Le partage de poids est illustré sur la figure ci-dessus. Supposons que nous ayons une couche qui a 4 neurones d'entrée et 4\n",
    "neurones de sortie, le poids est une matrice 4 × 4. A gauche se trouve la matrice de poids 4 × 4. Les poids sont quantifiés/regroupés en 4 groupes (4 couleurs),\n",
    "tous les poids dans le même groupe partagent la même valeur, donc pour chaque poids, il faut alors stocker uniquement\n",
    "un petit index dans une table de poids partagés. \n",
    "\n",
    "Le gain de mémoire peut se calculer en exprimant le taux de compression analytiquement. Pour un réseau avec $n$ connexions, où chacune stocke son poids correspondant sur un espace mémoire de $b$ bits, il faudra $nb$ bits pour stocker la matrice de poids.\n",
    "\n",
    "Si l'on regroupe ces poids en $k$ groupes, il nous faudra pour chaque connexion $log_2(k)$ bits pour stocker l'index renvoyant à un de ces $k$ groupes ainsi que $kb$ bits pour stocker ces poids en question.\n",
    "\n",
    "Le taux de compression est donc donné par:\n",
    "\n",
    "$$ r = \\frac{nb}{n log_2(k) + kb}$$\n",
    "\n",
    "### Clustering\n",
    "\n",
    "Nous utilisons le clustering k-means pour identifier les poids partagés pour chaque couche du réseau, de sorte que tous les poids qui tombent dans le même cluster partageront le même poids. Les poids ne sont pas partagés entre couches. \n",
    "\n",
    "Nous partitionnons les $n$ poids originaux $W = {w_1, w_2, ..., w_n}$ en $k$ clusters $C = {c_1, c_2, ..., c_k}$ avec $n >> k$, en de minimisant la somme des carrés intra-cluster:\n",
    "\n",
    "$$\\arg\\limits_{C} \\min \\sum_{i=1} ^{k} \\sum_{w \\in c_i} |w - c_i|^2 $$\n",
    "\n",
    "##### Initialisation des centres\n",
    "\n",
    "L'initialisation des centres a un impact sur la qualité du clustering et affecte donc la précision de la prédiction du réseau. Il existe trois méthodes d'initialisation qui sont discuté dans [[1]](#bib): \n",
    "\n",
    "- Forgy (aléatoire), basée sur une densité linéaire d'initialisation.\n",
    "\n",
    "- Initialisation basée sur la fonction de distribution des poids.\n",
    "\n",
    "- L'initialisation linéaire:  Espace linéairement les centres de gravité entre les [min, max] des poids d'origine.\n",
    "\n",
    "Il en sort de [[1]](#bib) que la meilleur méthode est l'initialisation linéaire et nous allons donc l'implémenter dans la suite de ce notebook. Cette méthode d'initialisation est invariante à la distribution des poids et est la plus dispersée par rapport aux deux premières méthodes (les poids représentant les $k$ groupes sont les plus différents).\n",
    "\n",
    "Les poids plus élevés jouent un rôle plus important que les poids plus petits, mais les poids important sont moins nombreux. Ainsi pour l'initialisation Forgy et l'initialisation basée sur la densité, très peu de centres de gravité ont une valeur élevée, ce qui se traduit par une mauvaise représentation de ces quelques grands poids. L'initialisation linéaire ne souffre pas de ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\32474\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:932: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\32474\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:932: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n",
      "C:\\Users\\32474\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:932: FutureWarning: 'precompute_distances' was deprecated in version 0.23 and will be removed in 0.25. It has no effect\n",
      "  warnings.warn(\"'precompute_distances' was deprecated in version \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csc_matrix, csr_matrix\n",
    "\n",
    "bits = 4\n",
    "\n",
    "for module in model.children():\n",
    "        weight = module.weight.data.cpu().numpy()\n",
    "        shape = weight.shape\n",
    "        mat = csr_matrix(weight) if shape[0] < shape[1] else csc_matrix(weight)\n",
    "        min_ = min(mat.data)\n",
    "        max_ = max(mat.data)\n",
    "        space = np.linspace(min_, max_, num=2**bits)\n",
    "        kmeans = KMeans(n_clusters=len(space), init=space.reshape(-1,1), n_init=1, precompute_distances=True, algorithm=\"full\")\n",
    "        kmeans.fit(mat.data.reshape(-1,1))\n",
    "        new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(-1)\n",
    "        mat.data = new_weight\n",
    "        module.weight.data = torch.from_numpy(mat.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- accuacy after weight sharing ---\n",
      "Test set: Average loss: 0.0924, Accuracy: 970/1000 (97.00%)\n",
      "tensor([-0.1960,  0.0000,  0.0000,  0.0000, -0.1262, -0.1960, -0.2385,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.1960, -0.1622,  0.1841,  0.0000,\n",
      "        -0.1622,  0.0000,  0.1508,  0.0000, -0.1262,  0.0000, -0.2830,  0.1508,\n",
      "         0.0000, -0.1262,  0.0000, -0.2385,  0.0000,  0.0000, -0.2830,  0.0000,\n",
      "         0.0000, -0.1960,  0.0000,  0.0000,  0.0000, -0.1960,  0.0000,  0.1841,\n",
      "         0.0000, -0.1262, -0.2830,  0.0000, -0.1622,  0.0000, -0.1960, -0.1960,\n",
      "         0.1658,  0.0000,  0.1841,  0.0000, -0.1262,  0.0000,  0.0000, -0.1262,\n",
      "         0.0000,  0.2584,  0.0000,  0.0000, -0.1622,  0.1225,  0.0000,  0.0000,\n",
      "         0.0000, -0.2830,  0.1225,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.1262,  0.0000,  0.1370, -0.3267,  0.0000,  0.1841,  0.0000,\n",
      "        -0.1262, -0.1622,  0.0000,  0.0000,  0.1370,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.1225,  0.1658,  0.0000,  0.0000,\n",
      "         0.0000,  0.1508,  0.0000,  0.0000], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print('--- accuacy after weight sharing ---')\n",
    "test()\n",
    "print(model.fc3.weight[0])\n",
    "#print(model.fc3.mask[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nouveau vous pouvez jouer avec le paramètre **bits** et réduire le nombre de bits utilisés pour encoder les différents poids (c'est à dire le nombre de cluster) et observer comment la précision du modèle évolue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complement\n",
    "\n",
    "Pour terminer cette étape du partage des poids, il peut être intéressant d'entrainer à nouveau notre modèle pour ajuster finement la valeur partagée de ces poids. Pour ce faire durant la back-propagation, les gradients de chaque poids d'un même groupe sont additionnés afin de modifier le poids partagé. Cette étape est explicitée dans la figure ci-dessous pour l'exemple précédent d'une matrice 4 x 4.\n",
    "\n",
    "<img src=\"img/finetuned.png\" width=\"50%\"> (© [[1]](#bib))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"bib\"> Bibliographie</a>\n",
    "\n",
    "[1] *Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding*, 2015, Song Han, Huizi Mao, William J. Dally\n",
    "\n",
    "[2] *Compact Neural Representation Using Attentive Network Pruning*, 2020, Mahdi Biparva, John Tsotsos.\n",
    "\n",
    "[3] *Noiseout: A simple way to prune neural networks*, arXiv preprint arXiv:1611.06211 (2016), Babaeizadeh, Mohammad, Paris Smaragdis, and Roy H. Campbell.\n",
    "\n",
    "[4] *Learning both Weights and Connections for Efficient Neural Networks*, 2015 Song Han, Jeff Pool, John Tran, William J. Dally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
